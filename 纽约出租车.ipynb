{
 "cells": [
  {
   "source": [
    "# 下一站去哪\n",
    "\n",
    "---\n",
    "\n",
    "## 概述\n",
    "\n",
    "这个notebook主要对纽约出租车一年半（2019-01到2020-06）的数据进行数据清洗，分析，可视化，建模等方面的操作\n",
    "\n",
    "数据来源：\n",
    "\n",
    "<https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page>\n",
    "\n",
    "\n",
    "数据描述：\n",
    "\n",
    "<https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf>\n",
    "\n",
    "数据文件夹结构\n",
    "\n",
    "需创建文件夹并将原始数据下载到data/raw\n",
    "\n",
    "```\n",
    "├─data/     # 保存数据\n",
    "│  ├─clear/ # 清洗后数据集\n",
    "│  ├─diff/  # 上下车差值\n",
    "│  ├─dist/  # 区域间距离\n",
    "│  ├─model/ # 模型\n",
    "│  └─raw/   # 原始数据\n",
    "├─graph/    # 保存图片\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "导入相关包"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "## 观察数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/raw/yellow_tripdata_2020-06.csv\")\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "profiling分析"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "pfr = pandas_profiling.ProfileReport(data)\n",
    "pfr.to_file('report.html')"
   ]
  },
  {
   "source": [
    "## 数据分析\n",
    "\n",
    "### 变量分析\n",
    "\n",
    "对profiling得到的报告进行分析\n",
    "\n",
    "|变量|含义|类型|待处理|\n",
    "|:-|:-|:-|:-|\n",
    "|VendorID|记录提供商|Categorical|缺省9.2%|\n",
    "|tpep_pickup_datetime|上车时间|Datetime||\n",
    "|tpep_dropoff_datetime|下车时间|Datetime||\n",
    "|passenger_count|乘客数量|Categorical Number|缺省9.2%，零值2.4%|\n",
    "|trip_distance|打车距离|Contiguous Number|零值3.2%，存在异常值(极大值)|\n",
    "|RatecodeID|价格代码|Categorical Number|缺省9.2%|\n",
    "|store_and_fwd_flag|是否保存在车辆内存中|Boolean|缺省9.2%|\n",
    "|PULocationID|上车区域ID|Categorical Number||\n",
    "|DOLocationID|下车区域ID|Categorical Number||\n",
    "|payment_type|支付类别|Categorical Number|缺省9.2%|\n",
    "|fare_amount|距离计价|Contiguous Number|存在异常值(负值，极大值)|\n",
    "|extra|附加费|Contiguous Number|零值47.8%(正常)|\n",
    "|mta_tax|交通税|Categorical Number|两类|\n",
    "|tip_amount|小费|Contiguous Number|零值41.0%(正常)|\n",
    "|tolls_amount|过路费|Contiguous Number|零值94.7%(正常)，存在异常值(极大值)|\n",
    "|improvement_surcharge|改善附加费|Categorical Number|两类，存在异常值(负值)|\n",
    "|total_amount|总费用|Contiguous Number|存在异常值(负值，极大值)|\n",
    "|congestion_surcharge|拥挤附加费|Categorical Number|两类，存在异常值(负值)|"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 想法提出\n",
    "\n",
    "我们可以使用的数据已在上面列出，我们通过几天的思考，决定了最后的idea\n",
    "\n",
    "**我们想做的是合理的调度出租车，给空闲的出租车下一站应去哪里的推荐，我们主要考虑两个因素：**\n",
    "\n",
    "1. **需求**\n",
    "2. **距离**\n",
    "\n",
    "**鉴于我们能得到的数据，保留上车时间、下车时间、上车区域、下车区域，可以统计某个时间段（定为一个小时）内下车与上车的差值（空车辆/需求量），并统计得到区域间通勤的平均旅程距离，作为我们的参考值**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 数据清洗\n",
    "\n",
    "鉴于我们的需求，我们保留了所需的几个数据，去重，去异常值，并添加了几个可能需要的变量"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data(filename, write = True):\n",
    "    year_month = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    print(\"Clearing file %s ...\" % filename)\n",
    "    # 保留需要使用的数据\n",
    "    n_data = data[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_distance', 'PULocationID', 'DOLocationID']]\n",
    "\n",
    "    # 去掉行进距离为0的数据\n",
    "    n_data = n_data[~n_data['trip_distance'].isin([0])]\n",
    "\n",
    "    # 计算行进时间，单位s\n",
    "    n_data['duration'] = (pd.to_datetime(n_data['tpep_dropoff_datetime'] ) - pd.to_datetime(n_data['tpep_pickup_datetime'])).dt.total_seconds()\n",
    "\n",
    "    # 去掉行进时间非正的数据\n",
    "    n_data = n_data[~(n_data['duration'] <= 0)]\n",
    "\n",
    "    # 计算行进速度，单位m/s\n",
    "    n_data['speed'] = (n_data['trip_distance']/n_data['duration'])*1000\n",
    "\n",
    "    # 去掉行进速度中过高的异常值，阈值为30m/s\n",
    "    n_data = n_data[~(n_data['speed'] > 30)]\n",
    "\n",
    "    # 去掉行进时间中过高的异常值，阈值为14400s，即4小时\n",
    "    n_data = n_data[~(n_data['duration'] > 14400)]\n",
    "\n",
    "    if write:\n",
    "        n_data.to_csv(\"data/clear/111new_yellow_tripdata_%s.csv\" % (year_month))\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(\"data/raw\"):\n",
    "    for f in files:\n",
    "        filename = os.path.join(root, f)\n",
    "        start = time.time()\n",
    "        clear_data(filename)\n",
    "        print(\"Cost time: %.2fs\" % (time.time() - start))\n",
    "        print(\"--------\" * 10)"
   ]
  },
  {
   "source": [
    "## 数据获取\n",
    "\n",
    "### 上下车差值\n",
    "\n",
    "有1-265个区域，我们以一个小时为观测时间，该段时间内该区域下车记录减去上车记录，存在正负值（负值表示上车的车辆数更多）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_format =\"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "def cal_diff(filename, write = True):\n",
    "    data = pd.read_csv(filename).drop(columns=['Unnamed: 0'])\n",
    "    year_month = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "    \n",
    "    start_time = datetime.strptime(year_month, \"%Y-%m\")\n",
    "    end_time = start_time + relativedelta(months = 1)\n",
    "\n",
    "    # start_time = \"2020-6-1 00:00:00\"\n",
    "    # end_time = \"2020-6-2 00:00:00\"\n",
    "\n",
    "    # start_time = datetime.strptime(start_time, time_format)\n",
    "    # end_time = datetime.strptime(end_time, time_format)\n",
    "\n",
    "    data[\"tpep_pickup_datetime\"] = pd.to_datetime(data[\"tpep_pickup_datetime\"])\n",
    "    data[\"tpep_dropoff_datetime\"] = pd.to_datetime(data[\"tpep_dropoff_datetime\"])\n",
    "\n",
    "    res_times = []\n",
    "    res_datas = []\n",
    "\n",
    "    print(\"Calculating file %s ...\" % filename)\n",
    "\n",
    "    while start_time < end_time:\n",
    "        # print(start_time)\n",
    "        # res_times.append(datetime.strftime(start_time, time_format))\n",
    "        res_times.append(start_time)\n",
    "        \n",
    "        tmp = start_time + timedelta(hours = 1)\n",
    "\n",
    "        # 对每个小时进行统计\n",
    "        res_data = np.zeros(265, dtype=np.int)\n",
    "\n",
    "        pickup = data.loc[(data[\"tpep_pickup_datetime\"] > start_time) & (data[\"tpep_pickup_datetime\"] < tmp)][\"PULocationID\"]\n",
    "        pickup.reset_index(drop=True, inplace=True)\n",
    "        dropoff = data.loc[(data[\"tpep_dropoff_datetime\"] > start_time) & (data[\"tpep_dropoff_datetime\"] < tmp)][\"DOLocationID\"]\n",
    "        dropoff.reset_index(drop=True, inplace=True)\n",
    "        for i in range(pickup.shape[0]):\n",
    "            res_data[pickup[i] - 1] -= 1\n",
    "        for i in range(dropoff.shape[0]):\n",
    "            res_data[dropoff[i] - 1] += 1\n",
    "        \n",
    "        res_datas.append(res_data)\n",
    "\n",
    "        start_time = tmp\n",
    "\n",
    "    res_times = pd.DataFrame(np.array(res_times)).rename(columns = {0: 'time'})\n",
    "    res_datas = pd.DataFrame(np.array(res_datas))\n",
    "\n",
    "    res = pd.concat([res_times, res_datas], axis = 1)\n",
    "    if write:\n",
    "        res.to_csv(\"data/diff/%s.csv\" % (year_month), index=False)\n",
    "    print(\"Done!\")\n",
    "    return res\n",
    "\n",
    "# cal_diff(\"data/clear_data/new_yellow_tripdata_2020-06.csv\")"
   ]
  },
  {
   "source": [
    "我们对数据清洗过的一年半的数据进行差值计算"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(\"data/clear\"):\n",
    "    for f in files:\n",
    "        filename = os.path.join(root, f)\n",
    "        start = time.time()\n",
    "        cal_diff(filename)\n",
    "        print(\"Cost time: %.2fs\" % (time.time() - start))\n",
    "        print(\"--------\" * 10)"
   ]
  },
  {
   "source": [
    "对上述我们获取的数据进行可视化，动态的时间变化可以更好的帮助我们观察数据\n",
    "\n",
    "`matplotlib画图`\n",
    "\n",
    "下面的一些属性可以帮助我们更好的观察想要的文件"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/diff/2020-06.csv\" # diff文件名\n",
    "frames = 100 # 展示帧数\n",
    "pause = 0.1 # 暂停时间，单位s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = cal_diff(\"data/clear_data/new_yellow_tripdata_2020-06.csv\", write=False)\n",
    "res = pd.read_csv(filename)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用自己的matplotlib后端，具体可看附录\n",
    "%matplotlib qt\n",
    "\n",
    "res_datas = res.iloc[:, 1:]\n",
    "res_times = res.iloc[:, 0]\n",
    "\n",
    "# print(res_times)\n",
    "# print(res_datas.index)\n",
    "\n",
    "# 创建画布\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "for i in range(res.shape[0]):\n",
    "\n",
    "    if i == frames:\n",
    "        break\n",
    "\n",
    "    plt_data = res_datas.loc[i]\n",
    "    plt_data.index = plt_data.index.astype(int)\n",
    "\n",
    "    # 正值 0-20 红色\n",
    "    plt_data0 = plt_data.loc[(plt_data > 0) & (plt_data <= 20)]\n",
    "    # 负值 -20-0 蓝色\n",
    "    plt_data1 = plt_data.loc[(plt_data < 0) & (plt_data >= -20)]\n",
    "    \n",
    "    # 超过可视化区域 >20 橙色\n",
    "    plt_data2 = plt_data.loc[plt_data > 20]\n",
    "    # 超过可视化区域 <20 紫色\n",
    "    plt_data3 = plt_data.loc[plt_data < -20]\n",
    "\n",
    "    plt.cla()\n",
    "\n",
    "    plt.xlabel('区域ID', fontsize=20)\n",
    "    plt.ylabel('下车-上车', fontsize=20)\n",
    "    plt.xlim([0, 264])\n",
    "    plt.ylim([-20, 20])\n",
    "\n",
    "    plt.title(res_times[i], fontsize=30)\n",
    "\n",
    "    bar0 = plt.bar(x=plt_data0.index.values, height=plt_data0, color='r')\n",
    "    bar1 = plt.bar(x=plt_data1.index.values, height=plt_data1, color='b')\n",
    "    bar2 = plt.bar(x=plt_data2.index.values, height=plt_data2, color='orange')\n",
    "    bar3 = plt.bar(x=plt_data3.index.values, height=plt_data3, color='purple')\n",
    "    # print(plt_data3.index.values)\n",
    "    for a, b in zip(plt_data2.index.values, plt_data2):\n",
    "        text0 = plt.text(a - 6, 18.5, '%.0f'%b, ha = 'center', va = 'bottom', fontsize=20, color='orange')\n",
    "    for a, b in zip(plt_data3.index.values, plt_data3):\n",
    "        text1 = plt.text(a - 6, -20, '%.0f'%b, ha = 'center', va = 'bottom', fontsize=20, color='purple')\n",
    "\n",
    "    plt.pause(pause)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "由于matplotlib可视化的展示的局限性及不够美观，我们使用pyecharts作为可视化工具\n",
    "\n",
    "`pyecharts热力图`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import HeatMap\n",
    "from pyecharts.charts import Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/diff/2019-01.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "days = int(data.shape[0] / 24)\n",
    "data['date'] = pd.to_datetime(data['time']).dt.date\n",
    "\n",
    "tl = (\n",
    "    Timeline(init_opts=opts.InitOpts(width='1500px',height='800px'))\n",
    "    .add_schema(play_interval=1000,is_auto_play=False)\n",
    "    )\n",
    "    \n",
    "x = [i for i in range(265)]\n",
    "y = [i for i in range(24)]\n",
    "for i in range(days):\n",
    "    value = [[k, j, int(data.iloc[i*24+j][k+1])] for k in range(265) for j in range(24)]\n",
    "    c = (\n",
    "        HeatMap()\n",
    "        .add_xaxis(x)\n",
    "        .add_yaxis(str(data.iloc[i*24]['date']), y, value)\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"2019年1月全部地区热力图\"),\n",
    "            visualmap_opts=opts.VisualMapOpts(min_=-30, max_=30),\n",
    "        )\n",
    "    )\n",
    "    tl.add(c, \"{}日\".format(i+1))\n",
    "tl.render(\"graph/heatmap_all.html\")"
   ]
  },
  {
   "source": [
    "由于全部的数据过于庞大，我们配置的限制和观测的不够清楚我们希望找到局部帮助我们观察，我们看到红蓝色居于比较显著的有两个部分，130-160，220-265部分，不过我们先不急着确定"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 区域间旅程距离\n",
    "\n",
    "计算一个265x265的数组表示各个区域间平均旅程距离"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/clear_data/new_yellow_tripdata_2020-06.csv\"\n",
    "data = pd.read_csv(filename).drop(columns=['Unnamed: 0'])[['trip_distance', \"PULocationID\", \"DOLocationID\"]]\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "统计一个月记录下的平均距离"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_dist(filename, write = True):\n",
    "    year_month = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    data = pd.read_csv(filename).drop(columns=['Unnamed: 0'])[['trip_distance', \"PULocationID\", \"DOLocationID\"]]\n",
    "\n",
    "    dist = np.zeros((265, 265))\n",
    "    cnt = np.zeros((265, 265), dtype=np.int)\n",
    "\n",
    "    print(\"Calculating file %s ...\" % filename)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(data.shape[0]):\n",
    "\n",
    "        if (i + 1) % 200000 == 0:\n",
    "            print(\"%d: cost time %.2fs\" %(i + 1, time.time() - start))\n",
    "            start = time.time()\n",
    "\n",
    "        tmp = data.loc[i]\n",
    "        d = tmp[\"trip_distance\"]\n",
    "        id1 = int(tmp[\"PULocationID\"]) - 1\n",
    "        id2 = int(tmp[\"DOLocationID\"]) - 1\n",
    "        \n",
    "        dist[id1, id2] = dist[id1, id2] + d\n",
    "        dist[id2, id1] = dist[id1, id2]\n",
    "        cnt[id1, id2] = cnt[id1, id2] + 1\n",
    "        cnt[id2, id1] = cnt[id1, id2]\n",
    "\n",
    "    cnt[np.where(cnt == 0)] = 1\n",
    "    res = dist / cnt\n",
    "\n",
    "    res = pd.DataFrame(res)\n",
    "    if write:\n",
    "        res.to_csv(\"data/dist/%s.csv\" % (year_month), index=False)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "source": [
    "计算一个月740w条数据约20分钟"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for root, dirs, files in os.walk(\"data/clear_data\"):\n",
    "    for f in files:\n",
    "        if i == 2: # 只读取几个文件\n",
    "            break\n",
    "        i += 1\n",
    "        filename = os.path.join(root, f)\n",
    "        start = time.time()\n",
    "        cal_dist(filename)\n",
    "        print(\"Cost time: %.2fs\" % (time.time() - start))\n",
    "        print(\"--------\" * 10)"
   ]
  },
  {
   "source": [
    "由于数据量过于庞大，我们先只关注两个月的数据，将2019-01与2019-02的数据做差，用pyecharts画出热力图，观察哪一部分的数据变化的最小"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist2 = pd.read_csv(\"data/dist/2019-02.csv\")\n",
    "dist1 = pd.read_csv(\"data/dist/2019-01.csv\")\n",
    "dist = dist1-dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制地区之间距离热度图\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import HeatMap\n",
    "\n",
    "x = [i for i in range(265)]\n",
    "y = [i for i in range(265)]\n",
    "value = [[i, j, int(dist.iloc[i][j])] for i in range(265) for j in range(265)]\n",
    "c = (\n",
    "    HeatMap(init_opts=opts.InitOpts(width='1000px',height='900px'))\n",
    "    .add_xaxis(x)\n",
    "    .add_yaxis(\"distance\", y, value)\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"各地区距离\"),\n",
    "        visualmap_opts=opts.VisualMapOpts(min_=-30, max_=30),\n",
    "    )\n",
    "    .render(\"graph/heatmap_diff.html\")\n",
    ")"
   ]
  },
  {
   "source": [
    "我们发现220-265部分变化会更小，所以我们最终选择这部分数据做分析及模型预测"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "部分地区热度图观察"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制一个月内部分区域的出租车热度图\n",
    "filename = \"data/diff/2019-01.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "days = int(data.shape[0] / 24)\n",
    "data['date'] = pd.to_datetime(data['time']).dt.date\n",
    "\n",
    "tl = (\n",
    "    Timeline(init_opts=opts.InitOpts(width='1500px',height='800px'))\n",
    "    .add_schema(play_interval=200,is_auto_play=False)\n",
    "    )\n",
    "    \n",
    "x = [i for i in range(220,265)]\n",
    "y = [i for i in range(24)]\n",
    "for i in range(days):\n",
    "    value = [[k, j, int(data.iloc[i*24+j][k+221])] for k in range(45) for j in range(24)]\n",
    "    c = (\n",
    "        HeatMap()\n",
    "        .add_xaxis(x)\n",
    "        .add_yaxis(str(data.iloc[i*24]['date']), y, value)\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"2019年1月部分地区热力图\"),\n",
    "            visualmap_opts=opts.VisualMapOpts(min_=-30, max_=30),\n",
    "        )\n",
    "    )\n",
    "    tl.add(c, \"{}日\".format(i+1))\n",
    "tl.render(\"graph/heatmap.html\")"
   ]
  },
  {
   "source": [
    "对上述部分进行分析：\n",
    "\n",
    "* 某些地区早上红色、晚上蓝色，可能是办公楼\n",
    "* 某些地区早上蓝色、晚上红色，可能是住宅区\n",
    "* ..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 模型搭建\n",
    "\n",
    "通过观察分析，对我们挑选出的一些数据（由于全数据集较大）进行模型搭建：\n",
    "\n",
    "区域ID：220-264\n",
    "\n",
    "`模型`\n",
    "\n",
    "一个图表示\n",
    "\n",
    "* 节点：上下车的差值\n",
    "  * 正，表示下车的出租数量更多（假设为空车数）\n",
    "  * 负，表示上车的出租数量更多（假设为需求数）\n",
    "* 边：出租车建议去下个区域的推荐值\n",
    "  * 主要由我们统计得到的区域间距离及该时间段该区域的上下车差值估计的推荐值"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 数据获取\n",
    "\n",
    "选定区域间trip距离的估计我们认为随时间变化不大，所以仅选择了2019-01月作为代表"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/dist/2019-01.csv\").iloc[220:265, 220:265]\n",
    "data.to_csv(\"data/model/dist.csv\", index = False)"
   ]
  },
  {
   "source": [
    "同理，2019-01，月平均每一个小时上下车差值"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/diff/2019-01.csv\").iloc[:, 221:]\n",
    "days = data.shape[0] // 24\n",
    "mean = data.iloc[0:24].values\n",
    "for i in range(1,days):\n",
    "    tmp = data.iloc[i*24: (i + 1) * 24].values\n",
    "    mean = mean + tmp\n",
    "mean = mean / days\n",
    "mean = pd.DataFrame(mean)\n",
    "mean.columns = range(220,265)\n",
    "mean.to_csv(\"data/model/diff.csv\", index = False)"
   ]
  },
  {
   "source": [
    "### 边的权重\n",
    "\n",
    "推荐值\n",
    "\n",
    "$\n",
    "weight_{i, j} = \n",
    "\\begin{cases}\n",
    "\\left|{\\frac{diff_i \\times diff_j}{dist_{i,j}}}\\right|, & if\\quad diff_i > 0\\quad and\\quad diff_j < 0 \\\\\n",
    "0, & otherwise\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$weight_{i, j}$表示有向边i -> j的权重，$diff_i$表示节点i的值（空车数），$diff_j$表示节点j的值（需求数），$dist_{i, j}$表示节点i到j的旅途距离"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.read_csv(\"data/model/dist.csv\")\n",
    "diff = pd.read_csv(\"data/model/diff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for t in range(24):\n",
    "    weights = np.zeros((45, 45))\n",
    "    for i in range(45):\n",
    "        for j in range(45):\n",
    "            diff_i = diff.iloc[t, i]\n",
    "            diff_j = diff.iloc[t, j]\n",
    "            dist_i_j = dist.iloc[i, j]\n",
    "            if diff_i > 0 and diff_j < 0 and dist_i_j != 0:\n",
    "                weights[i, j] = abs(diff_i * diff_j / dist_i_j)\n",
    "                # print(diff_i, diff_j, dist_i_j, weights[i, j])\n",
    "            else:\n",
    "                continue\n",
    "    res.append(weights)\n",
    "\n",
    "res = np.array(res)\n",
    "np.save('data/model/graph.npy', res)"
   ]
  },
  {
   "source": [
    "我们得到了一个矩阵存储需要的边权重\n",
    "\n",
    "节点的值由dist得到"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "`pyecharts关系图`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Timeline\n",
    "from pyecharts.charts import Graph"
   ]
  },
  {
   "source": [
    "判断节点颜色函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_color(n):\n",
    "    if n < 0:\n",
    "        return \"blue\"\n",
    "    if n > 0:\n",
    "        return \"red\"\n",
    "    return \"yellow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "\n",
    "tl = (Timeline(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\"))).add_schema(play_interval=500,is_auto_play=False)\n",
    "\n",
    "node = pd.read_csv(\"data/model/diff.csv\")\n",
    "edge = np.load(\"data/model/graph.npy\")\n",
    "\n",
    "for k in range(24):\n",
    "    nodes = [\n",
    "        {\n",
    "            \"name\": str(i+220),\n",
    "            \"value\": node.iloc[k,i],\n",
    "            \"symbolSize\": math.log(1+abs(node.iloc[k,i]),1.08),\n",
    "            \"itemStyle\": {\"normal\": {\"color\": node_color(node.iloc[k,i])}},\n",
    "        }\n",
    "        for i in range(45)\n",
    "    ]\n",
    "    edges = []\n",
    "    for i in range(45):\n",
    "        for j in range(45):\n",
    "            if edge[k,i,j] != 0:\n",
    "                edges.append({\"source\":str(i+220), \"target\":str(j+220), \"value\":edge[k,i,j]})\n",
    "    c = (\n",
    "        Graph(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\"))\n",
    "        .add(\n",
    "            series_name=\"\",\n",
    "            nodes=nodes,\n",
    "            links=edges,\n",
    "            layout=\"circular\",\n",
    "            is_roam=True,\n",
    "            is_focusnode=True,\n",
    "            label_opts=opts.LabelOpts(is_show=False),\n",
    "            linestyle_opts=opts.LineStyleOpts(width=0.5, curve=0.3, opacity=0.7),\n",
    "        )\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=\"预测关系图\"))\n",
    "    )\n",
    "    tl.add(c, \"{}时\".format(k))\n",
    "tl.render(\"graph/predict.html\")"
   ]
  },
  {
   "source": [
    "## 附录"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "使用下列命令查看matplotlib使用的后端"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}